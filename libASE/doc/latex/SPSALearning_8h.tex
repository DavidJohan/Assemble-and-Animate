\hypertarget{SPSALearning_8h}{
\section{/home/david/ASE/src/control/strategies/SPSALearning/SPSALearning.h File Reference}
\label{SPSALearning_8h}\index{/home/david/ASE/src/control/strategies/SPSALearning/SPSALearning.h@{/home/david/ASE/src/control/strategies/SPSALearning/SPSALearning.h}}
}
{\tt \#include \char`\"{}ConfigASE.h\char`\"{}}\par
{\tt \#include \char`\"{}RewardCollector.h\char`\"{}}\par
{\tt \#include \char`\"{}Message.h\char`\"{}}\par
{\tt \#include $<$stdint.h$>$}\par
\subsection*{Classes}
\begin{CompactItemize}
\item 
struct \hyperlink{structSPSALearningMsg__t}{SPSALearningMsg\_\-t}
\item 
struct \hyperlink{structSPSALearningMsgByte__t}{SPSALearningMsgByte\_\-t}
\item 
struct \hyperlink{structSPSALearning__t}{SPSALearning\_\-t}
\end{CompactItemize}
\subsection*{Functions}
\begin{CompactItemize}
\item 
void \hyperlink{SPSALearning_8h_9e6fe5357cc2b5f038ca85257d485281}{SPSALearning\_\-init} (\hyperlink{structSPSALearning__t}{SPSALearning\_\-t} $\ast$process)
\item 
void \hyperlink{SPSALearning_8h_ac5e40ae5e1dbe8672cd05a449545b39}{SPSALearning\_\-reset} (\hyperlink{structSPSALearning__t}{SPSALearning\_\-t} $\ast$process, int random)
\item 
void \hyperlink{SPSALearning_8h_c225a5ff31096068ee5cace6f8f689ef}{SPSALearning\_\-update} (\hyperlink{structSPSALearning__t}{SPSALearning\_\-t} $\ast$process)
\item 
void \hyperlink{SPSALearning_8h_a447a875f8f17cdd4700e99c4838ad36}{SPSALearning\_\-ignoreUpdate} (\hyperlink{structSPSALearning__t}{SPSALearning\_\-t} $\ast$process)
\item 
int \hyperlink{SPSALearning_8h_3da803da8b5ac8e2097035ac59c7e521}{SPSALearning\_\-isReady} (\hyperlink{structSPSALearning__t}{SPSALearning\_\-t} $\ast$process)
\item 
float \hyperlink{SPSALearning_8h_081e9455ebee4286ce3ed6bd9c95eb35}{SPSALearning\_\-getReward} (\hyperlink{structSPSALearning__t}{SPSALearning\_\-t} $\ast$process)
\item 
void \hyperlink{SPSALearning_8h_9757635ea429d56d46ca89ef4425c633}{SPSALearning\_\-collectReward} (\hyperlink{structSPSALearning__t}{SPSALearning\_\-t} $\ast$process, float reward)
\item 
float \hyperlink{SPSALearning_8h_2eb985422cfd6484952e9628b11f3a0b}{SPSALearning\_\-getThetaNonPerturbed} (\hyperlink{structSPSALearning__t}{SPSALearning\_\-t} $\ast$process, int index)
\item 
float \hyperlink{SPSALearning_8h_59f8aebcfafaa0ba94e6c75b9bce778b}{SPSALearning\_\-getTheta} (\hyperlink{structSPSALearning__t}{SPSALearning\_\-t} $\ast$process, int index, int wrap)
\item 
void \hyperlink{SPSALearning_8h_5076aae2c78c64ef7ad7942ae38aaf51}{SPSALearning\_\-setTheta} (\hyperlink{structSPSALearning__t}{SPSALearning\_\-t} $\ast$process, float $\ast$theta)
\end{CompactItemize}


\subsection{Detailed Description}
This file provides an implementation of the simultaneous perturbation stochastic approximation (SPSA) method (by James C. Spall). It can be used for any optimization until now it has been used for online optimization of locomotion.

A number of variables, called theta, (scaled in the interval 0-1) are optimized based on a reward signal

\begin{Desc}
\item[See also:]\hyperlink{SPSACpgGait_8h}{SPSACpgGait.h} \end{Desc}
\begin{Desc}
\item[Date:]July 2009 \end{Desc}
\begin{Desc}
\item[Author:]David Johan Christensen, Modular Robotics Lab, University of Southern Denmark \end{Desc}
\begin{Desc}
\item[Note:]This software is distributed under the BSD open-source license. \end{Desc}


\subsection{Function Documentation}
\hypertarget{SPSALearning_8h_9757635ea429d56d46ca89ef4425c633}{
\index{SPSALearning.h@{SPSALearning.h}!SPSALearning\_\-collectReward@{SPSALearning\_\-collectReward}}
\index{SPSALearning\_\-collectReward@{SPSALearning\_\-collectReward}!SPSALearning.h@{SPSALearning.h}}
\subsubsection{\setlength{\rightskip}{0pt plus 5cm}void SPSALearning\_\-collectReward ({\bf SPSALearning\_\-t} $\ast$ {\em process}, \/  float {\em reward})}}
\label{SPSALearning_8h_9757635ea429d56d46ca89ef4425c633}


Set the reward (typically based on local sensor information or a reward message send from an external supervisor. \hypertarget{SPSALearning_8h_081e9455ebee4286ce3ed6bd9c95eb35}{
\index{SPSALearning.h@{SPSALearning.h}!SPSALearning\_\-getReward@{SPSALearning\_\-getReward}}
\index{SPSALearning\_\-getReward@{SPSALearning\_\-getReward}!SPSALearning.h@{SPSALearning.h}}
\subsubsection{\setlength{\rightskip}{0pt plus 5cm}float SPSALearning\_\-getReward ({\bf SPSALearning\_\-t} $\ast$ {\em process})}}
\label{SPSALearning_8h_081e9455ebee4286ce3ed6bd9c95eb35}


Get the reward received by the learning process. \hypertarget{SPSALearning_8h_59f8aebcfafaa0ba94e6c75b9bce778b}{
\index{SPSALearning.h@{SPSALearning.h}!SPSALearning\_\-getTheta@{SPSALearning\_\-getTheta}}
\index{SPSALearning\_\-getTheta@{SPSALearning\_\-getTheta}!SPSALearning.h@{SPSALearning.h}}
\subsubsection{\setlength{\rightskip}{0pt plus 5cm}float SPSALearning\_\-getTheta ({\bf SPSALearning\_\-t} $\ast$ {\em process}, \/  int {\em index}, \/  int {\em wrap})}}
\label{SPSALearning_8h_59f8aebcfafaa0ba94e6c75b9bce778b}


Get the learning variables (theta) with perturbation (new parameters to explore). \hypertarget{SPSALearning_8h_2eb985422cfd6484952e9628b11f3a0b}{
\index{SPSALearning.h@{SPSALearning.h}!SPSALearning\_\-getThetaNonPerturbed@{SPSALearning\_\-getThetaNonPerturbed}}
\index{SPSALearning\_\-getThetaNonPerturbed@{SPSALearning\_\-getThetaNonPerturbed}!SPSALearning.h@{SPSALearning.h}}
\subsubsection{\setlength{\rightskip}{0pt plus 5cm}float SPSALearning\_\-getThetaNonPerturbed ({\bf SPSALearning\_\-t} $\ast$ {\em process}, \/  int {\em index})}}
\label{SPSALearning_8h_2eb985422cfd6484952e9628b11f3a0b}


Get the learning variables (theta) without perturbing them (estimation of optimal value so far) \hypertarget{SPSALearning_8h_a447a875f8f17cdd4700e99c4838ad36}{
\index{SPSALearning.h@{SPSALearning.h}!SPSALearning\_\-ignoreUpdate@{SPSALearning\_\-ignoreUpdate}}
\index{SPSALearning\_\-ignoreUpdate@{SPSALearning\_\-ignoreUpdate}!SPSALearning.h@{SPSALearning.h}}
\subsubsection{\setlength{\rightskip}{0pt plus 5cm}void SPSALearning\_\-ignoreUpdate ({\bf SPSALearning\_\-t} $\ast$ {\em process})}}
\label{SPSALearning_8h_a447a875f8f17cdd4700e99c4838ad36}


Reset reward to zero without changing the variables \hypertarget{SPSALearning_8h_9e6fe5357cc2b5f038ca85257d485281}{
\index{SPSALearning.h@{SPSALearning.h}!SPSALearning\_\-init@{SPSALearning\_\-init}}
\index{SPSALearning\_\-init@{SPSALearning\_\-init}!SPSALearning.h@{SPSALearning.h}}
\subsubsection{\setlength{\rightskip}{0pt plus 5cm}void SPSALearning\_\-init ({\bf SPSALearning\_\-t} $\ast$ {\em process})}}
\label{SPSALearning_8h_9e6fe5357cc2b5f038ca85257d485281}


Initialize the learning process with default parameters \hypertarget{SPSALearning_8h_3da803da8b5ac8e2097035ac59c7e521}{
\index{SPSALearning.h@{SPSALearning.h}!SPSALearning\_\-isReady@{SPSALearning\_\-isReady}}
\index{SPSALearning\_\-isReady@{SPSALearning\_\-isReady}!SPSALearning.h@{SPSALearning.h}}
\subsubsection{\setlength{\rightskip}{0pt plus 5cm}int SPSALearning\_\-isReady ({\bf SPSALearning\_\-t} $\ast$ {\em process})}}
\label{SPSALearning_8h_3da803da8b5ac8e2097035ac59c7e521}


If the learning process is ready to be updated. The condition is that it must have received a reward since the last update. \hypertarget{SPSALearning_8h_ac5e40ae5e1dbe8672cd05a449545b39}{
\index{SPSALearning.h@{SPSALearning.h}!SPSALearning\_\-reset@{SPSALearning\_\-reset}}
\index{SPSALearning\_\-reset@{SPSALearning\_\-reset}!SPSALearning.h@{SPSALearning.h}}
\subsubsection{\setlength{\rightskip}{0pt plus 5cm}void SPSALearning\_\-reset ({\bf SPSALearning\_\-t} $\ast$ {\em process}, \/  int {\em random})}}
\label{SPSALearning_8h_ac5e40ae5e1dbe8672cd05a449545b39}


Reset the variables (theta) to a random value between (0 to 1) if random = 1 otherwise to to 0.5 \hypertarget{SPSALearning_8h_5076aae2c78c64ef7ad7942ae38aaf51}{
\index{SPSALearning.h@{SPSALearning.h}!SPSALearning\_\-setTheta@{SPSALearning\_\-setTheta}}
\index{SPSALearning\_\-setTheta@{SPSALearning\_\-setTheta}!SPSALearning.h@{SPSALearning.h}}
\subsubsection{\setlength{\rightskip}{0pt plus 5cm}void SPSALearning\_\-setTheta ({\bf SPSALearning\_\-t} $\ast$ {\em process}, \/  float $\ast$ {\em theta})}}
\label{SPSALearning_8h_5076aae2c78c64ef7ad7942ae38aaf51}


Set the learning variables from an array of float (must have length equal to SPSA\_\-N\_\-PARAMETERS\_\-MAX). \hypertarget{SPSALearning_8h_c225a5ff31096068ee5cace6f8f689ef}{
\index{SPSALearning.h@{SPSALearning.h}!SPSALearning\_\-update@{SPSALearning\_\-update}}
\index{SPSALearning\_\-update@{SPSALearning\_\-update}!SPSALearning.h@{SPSALearning.h}}
\subsubsection{\setlength{\rightskip}{0pt plus 5cm}void SPSALearning\_\-update ({\bf SPSALearning\_\-t} $\ast$ {\em process})}}
\label{SPSALearning_8h_c225a5ff31096068ee5cace6f8f689ef}


Update variables (theta) in the learning process based on previously received reward and reset the reward to zero 